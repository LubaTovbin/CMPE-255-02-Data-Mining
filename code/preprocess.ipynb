{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import us_state_abbrev as states\n",
    "\n",
    "base_path = os.path.abspath(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_path = os.path.join(base_path, 'data/crime/')\n",
    "crime_dataframes = [os.path.join(crime_path, file) for file in os.listdir(crime_path)]\n",
    "\n",
    "def GetCrimeCountyNames(row):\n",
    "    state = row.name[0]\n",
    "    state = state.split(\"\\ue83a\")[0]\n",
    "    state = state.split(\"-\")[0]\n",
    "    state = state.lower().title().strip()\n",
    "    state_code = states.us_state_abbrev[state]\n",
    "    \n",
    "    county = row.name[1]\n",
    "    county = \"\".join([letter for letter in county if not letter.isnumeric()])\n",
    "    county = re.sub(\"County\" ,\"\", county)\n",
    "    county = re.sub(\"Police\" ,\"\", county)\n",
    "    county = re.sub(\"Department\" ,\"\", county)\n",
    "    county = county.strip()\n",
    "    \n",
    "    full_county = county + \", \" + state_code.strip()\n",
    "    \n",
    "    return full_county, state.upper()\n",
    "\n",
    "def GetCrimeDataFrame(files):\n",
    "    \n",
    "    dataframes = []\n",
    "    \n",
    "    for file in files:\n",
    "        df = pd.read_excel(file, index_col=[0,1], index_row=0, encoding='utf-8')\n",
    "        df.columns = df.columns.str.lower()\n",
    "        df[\"Area_name\"], df[\"state\"] = zip(*df.apply(lambda row: GetCrimeCountyNames(row), axis=1))\n",
    "        df = df.set_index(\"Area_name\")\n",
    "        df[\"total crime\"] = df.apply(lambda row: row[\"violent crime\"] + row[\"property crime\"], axis=1)\n",
    "        df[\"log violent crime\"] = df.apply(lambda row: np.log1p(row[\"violent crime\"]) if row[\"violent crime\"] != 0 else 0, axis=1)\n",
    "        df[\"log property crime\"] = df.apply(lambda row: np.log1p(row[\"property crime\"]) if row[\"property crime\"] != 0 else 0, axis=1)\n",
    "        df[\"log total crime\"] = df.apply(lambda row: np.log1p(row[\"total crime\"]) if row[\"total crime\"] != 0 else 0, axis=1)\n",
    "        df[\"root log violent crime\"] = df.apply(lambda row: np.power(row[\"log violent crime\"], 1/2), axis=1)\n",
    "        df[\"root log property crime\"] = df.apply(lambda row: np.power(row[\"log property crime\"], 1/2), axis=1)\n",
    "        df[\"root log total crime\"] = df.apply(lambda row: np.power(row[\"log total crime\"], 1/2), axis=1)\n",
    "        df.head()\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    final_columns = list(set.intersection(*map(set, [dframe.columns.tolist() for dframe in dataframes])))\n",
    "    crime_data = pd.concat(dataframes, sort=False)\n",
    "\n",
    "    state_map = crime_data[[\"Area_name\", \"state\"]].drop_duplicates()\n",
    "    crime_data = crime_data.drop([\"state\"])\n",
    "    \n",
    "    by_row_index = crime_data.groupby(crime_data.index)\n",
    "    crime_data = by_row_index.mean()\n",
    "    \n",
    "    final_columns = [col for col in final_columns if col != \"state\"]\n",
    "    crime_data = crime_data[final_columns]\n",
    "    \n",
    "    final_columns = [col.title() for col in final_columns]\n",
    "    crime_data.columns = final_columns\n",
    "    \n",
    "    crime_data = crime_data.fillna(0)\n",
    "    crime_data = crime_data.loc[crime_data[\"Total Crime\"] != 0.0]\n",
    "    \n",
    "    return crime_data, state_map\n",
    "\n",
    "def LoadCrimeData():\n",
    "    \n",
    "    crime_data, state_map = GetCrimeDataFrame(crime_dataframes)    \n",
    "    cols_to_return = [\"Property Crime\", \"Violent Crime\", \"Total Crime\", \"Log Property Crime\", \"Log Violent Crime\", \"Log Total Crime\", \"Root Log Property Crime\", \"Root Log Violent Crime\", \"Root Log Total Crime\"]\n",
    "    return crime_data[cols_to_return]\n",
    "\n",
    "def LoadViolentCrimeData():\n",
    "    crime_data = GetCrimeDataFrame(crime_dataframes)    \n",
    "    cols_to_return = [\"Murder And Nonnegligent Manslaughter\", \"Forcible Rape\", \"Robbery\", \"Aggravated Assault\"]\n",
    "    return crime_data[cols_to_return]\n",
    "\n",
    "def LoadPropertyCrimeData():\n",
    "    crime_data = GetCrimeDataFrame(crime_dataframes)    \n",
    "    cols_to_return = [\"Burglary\", \"Larceny-Theft\", \"Motor Vehicle Theft\", \"Arson1\"]\n",
    "    return crime_data[cols_to_return]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "violent crime  murder and nonnegligent manslaughter  \\\nArea_name                                                            \nAbbeville, SC      52.200000                                  0.20   \nAcadia, LA         45.000000                                  0.75   \nAccomack, VA       70.000000                                  3.00   \nAda, ID           159.333333                                  2.00   \nAdair, IA           4.600000                                  0.00   \n...                      ...                                   ...   \nYuma, AZ          149.400000                                  3.60   \nYuma, CO            5.250000                                  0.00   \nZapata, TX         36.000000                                  0.40   \nZavala, TX         21.000000                                  0.80   \nZiebach, SD         0.500000                                  0.00   \n\n               forcible rape    robbery  aggravated assault  property crime  \\\nArea_name                                                                     \nAbbeville, SC           2.40   2.200000               47.40          307.60   \nAcadia, LA              3.25   2.500000               38.50          569.25   \nAccomack, VA            8.00  28.200000               30.80          536.40   \nAda, ID                23.00   9.333333              125.00         1079.00   \nAdair, IA               0.20   0.000000                4.40           44.20   \n...                      ...        ...                 ...             ...   \nYuma, AZ                7.20  17.000000              121.60         1267.00   \nYuma, CO                1.00   0.000000                4.25           26.00   \nZapata, TX              1.40   2.600000               31.60          232.40   \nZavala, TX              0.80   1.200000               18.20           84.20   \nZiebach, SD             0.00   0.000000                0.50            4.00   \n\n                 burglary  larceny-theft  motor vehicle theft     arson1  \\\nArea_name                                                                  \nAbbeville, SC   93.400000         197.00            17.200000   3.000000   \nAcadia, LA     100.250000         418.00            51.000000   0.000000   \nAccomack, VA   152.000000         336.20            48.200000   1.200000   \nAda, ID        298.333333         732.00            48.666667  16.333333   \nAdair, IA       11.600000          28.80             3.800000   0.400000   \n...                   ...            ...                  ...        ...   \nYuma, AZ       381.600000         704.80           180.600000   9.200000   \nYuma, CO         5.250000          19.00             1.750000   0.250000   \nZapata, TX     103.600000         107.00            21.800000   0.600000   \nZavala, TX      36.400000          42.60             5.200000   1.600000   \nZiebach, SD      2.000000           0.75             1.250000   0.000000   \n\n               total crime  log violent crime  log property crime  \\\nArea_name                                                           \nAbbeville, SC   359.800000           3.967179            5.729779   \nAcadia, LA      614.250000           3.545000            6.327271   \nAccomack, VA    606.400000           4.255036            6.280119   \nAda, ID        1238.333333           5.075962            6.976657   \nAdair, IA        48.800000           1.602867            3.793328   \n...                    ...                ...                 ...   \nYuma, AZ       1416.400000           4.954268            7.105137   \nYuma, CO         31.250000           1.762314            3.263247   \nZapata, TX      268.400000           3.597606            5.424906   \nZavala, TX      105.200000           3.022946            4.386447   \nZiebach, SD       4.500000           0.346574            1.510064   \n\n               log total crime  root log violent crime  \\\nArea_name                                                \nAbbeville, SC         5.886334                1.991553   \nAcadia, LA            6.398918                1.873566   \nAccomack, VA          6.403138                2.062554   \nAda, ID               7.115527                2.252961   \nAdair, IA             3.896170                1.245159   \n...                        ...                     ...   \nYuma, AZ              7.215698                2.224504   \nYuma, CO              3.439134                1.317692   \nZapata, TX            5.579167                1.896254   \nZavala, TX            4.611116                1.735547   \nZiebach, SD           1.644813                0.416277   \n\n               root log property crime  root log total crime  \nArea_name                                                     \nAbbeville, SC                 2.393655              2.426142  \nAcadia, LA                    2.515094              2.529226  \nAccomack, VA                  2.505909              2.530346  \nAda, ID                       2.641227              2.667405  \nAdair, IA                     1.947030              1.973473  \n...                                ...                   ...  \nYuma, AZ                      2.664986              2.685651  \nYuma, CO                      1.805048              1.853069  \nZapata, TX                    2.328537              2.361686  \nZavala, TX                    2.092667              2.145884  \nZiebach, SD                   1.208679              1.274344  \n\n[2732 rows x 17 columns]\n"
    },
    {
     "ename": "KeyError",
     "evalue": "\"['state'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1b4e0ae0acd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGetCrimeDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrime_dataframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-351ac9c42e68>\u001b[0m in \u001b[0;36mGetCrimeDataFrame\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcrime_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby_row_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrime_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mcrime_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrime_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mfinal_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mcrime_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['state'] not in index\""
     ]
    }
   ],
   "source": [
    "crime_data, state_map = GetCrimeDataFrame(crime_dataframes)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_path = os.path.join(base_path, 'data/education/')\n",
    "\n",
    "def GetNoDegree(row):\n",
    "    \n",
    "    total = int(row[\"Total\"])\n",
    "    no_degree = int(row[\"High school graduate (includes equivalency)\"]) + int(row[\"Some college, no degree\"])\n",
    "    return ((1.00 - (float(no_degree)/float(total)))*100)\n",
    "\n",
    "\n",
    "def CleanEducationAttrName(row):\n",
    "    name = row[\"Attribute Name\"]\n",
    "    name = re.sub(r\"Educational attainment\", \"\", name)\n",
    "    name = re.sub(r\"Persons 25 years and over,\", \"\", name)\n",
    "    name = re.sub(r\"persons 25 years and over\", \"\", name)\n",
    "    name = re.sub(r\"2005-2009\", \"\", name)\n",
    "    name = re.sub(r\"\\s\\s+\", \" \", name)\n",
    "    name = re.sub(\"\\-\", \"\", name)\n",
    "    name = name.strip().capitalize()\n",
    "    return name\n",
    "\n",
    "def GetEducationDataFrame(education_path):\n",
    "    education_dataframes = [os.path.join(education_path, file) for file in os.listdir(education_path) if \"EDU\" in file]\n",
    "    \n",
    "    education_metadata = pd.read_excel(os.path.join(education_path, \"education_by_counties.xlsx\"))\n",
    "    education_metadata[\"Attribute Name\"] = education_metadata.apply(lambda row: CleanEducationAttrName(row), axis=1)\n",
    "\n",
    "    education_data = []\n",
    "\n",
    "    for idx, row in education_metadata.iterrows():\n",
    "        location = row[\"Location\"]\n",
    "        filename = location[:len(location)-1]\n",
    "        file = [x for x in education_dataframes if re.search(filename, x)][0]\n",
    "        df = pd.read_excel(file, location, index_col=0)\n",
    "        column = df.loc[:,[row[\"ID\"]]]\n",
    "        column = column.rename(columns = {row['ID']:row[\"Attribute Name\"]})\n",
    "        education_data.append(column)\n",
    "\n",
    "    education_data = pd.concat(education_data, axis=1)\n",
    "    education_data = education_data.loc[education_data[\"Total\"] != 0]\n",
    "    \n",
    "    return education_data\n",
    "\n",
    "\n",
    "def LoadEducationData():\n",
    "    \n",
    "    education_data = GetEducationDataFrame(education_path)\n",
    "    education_data[\"Percent High School Dropouts\"] = education_data.apply(lambda row: 100.00 - float(row[\"Percent high school graduate or higher\"]), axis=1)\n",
    "    education_data[\"Percent No Degree\"] = education_data.apply(lambda row: GetNoDegree(row), axis=1)\n",
    "    education_data[\"Percent Any Degree\"] = education_data.apply(lambda row: 100.00 - float(row[\"Percent No Degree\"]) - float(row[\"Percent High School Dropouts\"]), axis=1)\n",
    "    \n",
    "    return education_data[[\"Percent High School Dropouts\", \"Percent No Degree\", \"Percent Any Degree\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_path = os.path.join(base_path, 'data/income/')\n",
    "\n",
    "def GetIncomeRangeMeans():\n",
    "    income_range_means = {\n",
    "        \"Households with income less than \\$10,000\": 5000,\n",
    "        \"Households with income of \\$10,000 to \\$14,999\": 12500,\n",
    "        \"Households with income of \\$15,000 to \\$19,999\": 17500,\n",
    "        \"Households with income of \\$20,000 to \\$24,999\": 22500,\n",
    "        \"Households with income of \\$25,000 to \\$29,999\": 27500,\n",
    "        \"Households with income of \\$30,000 to \\$34,999\": 32500,\n",
    "        \"Households with income of \\$35,000 to \\$39,999\": 37500,\n",
    "        \"Households with income of \\$40,000 to \\$44,999\": 42500,\n",
    "        \"Households with income of \\$45,000 to \\$49,999\": 47500,\n",
    "        \"Households with income of \\$50,000 to \\$59,999\": 55000,\n",
    "        \"Households with income of \\$60,000 to \\$74,999\": 67500,\n",
    "        \"Households with income of \\$75,000 to \\$99,999\": 87500,\n",
    "        \"Households with income of \\$100,000 to \\$124,999\": 112500,\n",
    "        \"Households with income of \\$125,000 to \\$149,999\": 137500,\n",
    "        \"Households with income of \\$150,000 to \\$199,999\": 175000\n",
    "    }\n",
    "    return income_range_means\n",
    "\n",
    "income_range_means = GetIncomeRangeMeans()\n",
    "\n",
    "def GetIncomeStdDeviation(row):\n",
    "    \n",
    "    values, frequencies = [], []\n",
    "\n",
    "    total_income = int(row[\"Households with income, total\"]) * int(row[\"Mean Income (Household)\"])\n",
    "    total_high_bracket = int(row[\"Households with income of \\$200,000 or more\"])\n",
    "    columns_to_check = [str(x) for x in row.axes[0].tolist() if \"$\" in str(x) and \"more\" not in str(x)]\n",
    "    \n",
    "    total_without = 0\n",
    "    for c in columns_to_check:\n",
    "        values.append(float(income_range_means[c])/1000.0)\n",
    "        frequencies.append(int(row[c]))\n",
    "        total_without += int(row[c]) * float(income_range_means[c]/1000.0)\n",
    "    \n",
    "    remainder = total_income - total_without\n",
    "    high_bracket_mean = 0\n",
    "\n",
    "    if total_high_bracket != 0:\n",
    "        high_bracket_mean = float(remainder/total_high_bracket)\n",
    "    \n",
    "    values.append(int(high_bracket_mean))\n",
    "    frequencies.append(int(total_high_bracket))\n",
    "    \n",
    "    overall_income_data = np.repeat(np.array(values), np.array(frequencies))\n",
    "    std_dev = np.std(overall_income_data, dtype=np.float64, ddof=1)\n",
    "    \n",
    "    return std_dev, high_bracket_mean\n",
    "\n",
    "\n",
    "def CleanIncomeAttrName(row):\n",
    "    name = row[\"Attribute Name\"]\n",
    "    name = re.sub(r\" in the past 12 months \\(in 2009 inflation-adjusted dollars\\)\", \"\", name)\n",
    "    name = re.sub(r\"in 2005-2009\", \"\", name)\n",
    "    name = re.sub(r\"2005-2009\", \"\", name)\n",
    "    name = re.sub(r\"\\s\\s+\", \" \", name)\n",
    "    name = re.sub(\"\\$\", \"\\\\$\", name)\n",
    "    name = name.strip()\n",
    "    return name\n",
    "\n",
    "\n",
    "def GetIncomeDataFrame(income_path):\n",
    "\n",
    "    income_dataframes = [os.path.join(income_path, file) for file in os.listdir(income_path) if \"INC\" in file]\n",
    "\n",
    "    income_metadata = pd.read_excel(os.path.join(income_path, \"income_by_counties.xlsx\"))\n",
    "    income_metadata[\"Attribute Name\"] = income_metadata.apply(lambda row: CleanIncomeAttrName(row), axis=1)\n",
    "\n",
    "    income_data = []\n",
    "\n",
    "    for idx, row in income_metadata.iterrows():\n",
    "        location = row[\"Location\"]\n",
    "        filename = location[:len(location)-1]\n",
    "        file = [x for x in income_dataframes if re.search(filename, x)][0]\n",
    "        df = pd.read_excel(file, location, index_col=0)\n",
    "        column = df.loc[:,[row[\"ID\"]]]\n",
    "        column = column.rename(columns = {row['ID']:row[\"Attribute Name\"]})\n",
    "        income_data.append(column)\n",
    "\n",
    "    income_data = pd.concat(income_data, axis=1)\n",
    "    income_data = income_data.rename(columns = {\"Mean household income\": \"Mean Income (Household)\",\n",
    "                                            \"Median household income\": \"Median Income (Household)\",\n",
    "                                           \"Per capita income\": \"Per Capita Income\"})\n",
    "    income_data[\"Mean Income (Household)\"] = income_data[\"Mean Income (Household)\"].astype(float)/1000.00\n",
    "    income_data[\"Median Income (Household)\"] = income_data[\"Median Income (Household)\"].astype(float)/1000.00\n",
    "    income_data[\"Per Capita Income\"] = income_data[\"Per Capita Income\"].astype(float)/1000.00\n",
    "\n",
    "    income_data = income_data.loc[income_data[\"Mean Income (Household)\"] != 0.0]\n",
    "    income_data[\"Income Standard Deviation (Household)\"], income_data[\"High Bracket Income (Household)\"] = zip(*income_data.apply(lambda row: GetIncomeStdDeviation(row), axis=1))\n",
    "    \n",
    "    return income_data\n",
    "\n",
    "\n",
    "def LoadIncomeData():\n",
    "    \n",
    "    income_data = GetIncomeDataFrame(income_path)\n",
    "    return income_data[[\"Mean Income (Household)\", \"Median Income (Household)\", \n",
    "                        \"Per Capita Income\", \"Income Standard Deviation (Household)\", \"High Bracket Income (Household)\"]]   \n",
    "\n",
    "\n",
    "def LoadIncomeDistribution():\n",
    "\n",
    "    income_data = GetIncomeDataFrame(income_path)\n",
    "    income_range_means = GetIncomeRangeMeans()\n",
    "    income_range_means[\"Households with income of \\$200,000 or more\"] = income_data.loc[\"UNITED STATES\", \"High Bracket Income (Household)\"]*1000.00\n",
    "\n",
    "    columns_to_drop = [\"Median Income (Household)\", \"Mean Income (Household)\", \"Households with income, total\", \"Per Capita Income\",\n",
    "       \"Income Standard Deviation (Household)\", \"High Bracket Income (Household)\"]\n",
    "\n",
    "    income_data = income_data.drop(columns_to_drop, axis=1).loc[\"UNITED STATES\"]\n",
    "\n",
    "    final_data = income_data.rename(lambda x: float(income_range_means[x])/1000)\n",
    "\n",
    "    return final_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_data():\n",
    "    \n",
    "    file_path = os.path.join(base_path, 'preprocessed/education_income_crime.xlsx')\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        master_df = pd.read_excel(file_path, index_col=0)\n",
    "    \n",
    "    else:\n",
    "        crime_data = LoadCrimeData()\n",
    "        education_data = LoadEducationData()\n",
    "        income_data = LoadIncomeData()\n",
    "\n",
    "        master_df = crime_data.merge(income_data, on=\"Area_name\").merge(education_data, on=\"Area_name\")\n",
    "        master_df.to_excel(file_path)\n",
    "    \n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
} 2
}