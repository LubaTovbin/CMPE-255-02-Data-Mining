{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=reader.get_all_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting features and label and performing few transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class Row(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.education_type = None\n",
    "        self.income_type = None\n",
    "        self.crime_regularization = None\n",
    "        self.LinearRegMSE = None\n",
    "        self.RidgeMSE = None\n",
    "        self.DecisionTreeMSE = None\n",
    "        self.KNeighbourMSE = None\n",
    "        self.SVR_MSE = None\n",
    "        self.RandomForestMSE = None\n",
    "        self.BoostingMSE = None\n",
    "\n",
    "    def toDict(self):\n",
    "        return {'education_type' : self.education_type,\n",
    "                'income_type' : self.income_type,\n",
    "                'crime_regularization': self.crime_regularization,\n",
    "                'LinearRegMSE':  self.LinearRegMSE,\n",
    "                'RidgeMSE' : self.RidgeMSE,\n",
    "                'DecisionTreeMSE' : self.DecisionTreeMSE,\n",
    "                'KNeighbourMSE': self.KNeighbourMSE,\n",
    "                'SVR_MSE' : self.SVR_MSE,\n",
    "                'RandomForestMSE': self.RandomForestMSE,\n",
    "                'BoostingMSE' :self.BoostingMSE\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Applying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BoostingMSE</th>\n      <th>DecisionTreeMSE</th>\n      <th>KNeighbourMSE</th>\n      <th>LinearRegMSE</th>\n      <th>RandomForestMSE</th>\n      <th>RidgeMSE</th>\n      <th>SVR_MSE</th>\n      <th>crime_regularization</th>\n      <th>education_type</th>\n      <th>income_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.136757</td>\n      <td>0.142844</td>\n      <td>0.187286</td>\n      <td>0.135341</td>\n      <td>0.136757</td>\n      <td>0.135341</td>\n      <td>0.133981</td>\n      <td>Square Root of Log</td>\n      <td>High School Dropout Percent</td>\n      <td>Median Income</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.140936</td>\n      <td>0.150008</td>\n      <td>0.196002</td>\n      <td>0.145034</td>\n      <td>0.140936</td>\n      <td>0.145033</td>\n      <td>0.140423</td>\n      <td>Square Root of Log</td>\n      <td>High School Dropout Percent</td>\n      <td>Income Standard Deviation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.138107</td>\n      <td>0.141787</td>\n      <td>0.188993</td>\n      <td>0.134803</td>\n      <td>0.138107</td>\n      <td>0.134802</td>\n      <td>0.142382</td>\n      <td>Square Root of Log</td>\n      <td>Percent with Any Degree</td>\n      <td>Median Income</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.137959</td>\n      <td>0.140847</td>\n      <td>0.189016</td>\n      <td>0.137201</td>\n      <td>0.137959</td>\n      <td>0.137202</td>\n      <td>0.136058</td>\n      <td>Square Root of Log</td>\n      <td>Percent with Any Degree</td>\n      <td>Income Standard Deviation</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.020918</td>\n      <td>0.022114</td>\n      <td>0.029812</td>\n      <td>0.020799</td>\n      <td>0.020918</td>\n      <td>0.020799</td>\n      <td>0.020618</td>\n      <td>Fourth Root of Log</td>\n      <td>High School Dropout Percent</td>\n      <td>Median Income</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.022135</td>\n      <td>0.021925</td>\n      <td>0.030625</td>\n      <td>0.022015</td>\n      <td>0.022135</td>\n      <td>0.022014</td>\n      <td>0.021241</td>\n      <td>Fourth Root of Log</td>\n      <td>High School Dropout Percent</td>\n      <td>Income Standard Deviation</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.021310</td>\n      <td>0.021721</td>\n      <td>0.029206</td>\n      <td>0.020920</td>\n      <td>0.021310</td>\n      <td>0.020920</td>\n      <td>0.021868</td>\n      <td>Fourth Root of Log</td>\n      <td>Percent with Any Degree</td>\n      <td>Median Income</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.021465</td>\n      <td>0.021700</td>\n      <td>0.030082</td>\n      <td>0.021203</td>\n      <td>0.021465</td>\n      <td>0.021203</td>\n      <td>0.021044</td>\n      <td>Fourth Root of Log</td>\n      <td>Percent with Any Degree</td>\n      <td>Income Standard Deviation</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   BoostingMSE  DecisionTreeMSE  KNeighbourMSE  LinearRegMSE  RandomForestMSE  \\\n0     0.136757         0.142844       0.187286      0.135341         0.136757   \n1     0.140936         0.150008       0.196002      0.145034         0.140936   \n2     0.138107         0.141787       0.188993      0.134803         0.138107   \n3     0.137959         0.140847       0.189016      0.137201         0.137959   \n4     0.020918         0.022114       0.029812      0.020799         0.020918   \n5     0.022135         0.021925       0.030625      0.022015         0.022135   \n6     0.021310         0.021721       0.029206      0.020920         0.021310   \n7     0.021465         0.021700       0.030082      0.021203         0.021465   \n\n   RidgeMSE   SVR_MSE crime_regularization               education_type  \\\n0  0.135341  0.133981   Square Root of Log  High School Dropout Percent   \n1  0.145033  0.140423   Square Root of Log  High School Dropout Percent   \n2  0.134802  0.142382   Square Root of Log      Percent with Any Degree   \n3  0.137202  0.136058   Square Root of Log      Percent with Any Degree   \n4  0.020799  0.020618   Fourth Root of Log  High School Dropout Percent   \n5  0.022014  0.021241   Fourth Root of Log  High School Dropout Percent   \n6  0.020920  0.021868   Fourth Root of Log      Percent with Any Degree   \n7  0.021203  0.021044   Fourth Root of Log      Percent with Any Degree   \n\n                 income_type  \n0              Median Income  \n1  Income Standard Deviation  \n2              Median Income  \n3  Income Standard Deviation  \n4              Median Income  \n5  Income Standard Deviation  \n6              Median Income  \n7  Income Standard Deviation  "
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "param_grid = {\"education_type\" :[\"dropout\", \"degree\"], \"income_type\" :[\"median\", \"deviation\"], \"crime_type\":[\"log\", \"sqrt_log\"]}\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for param in list(ParameterGrid(param_grid)):\n",
    "    row = Row()\n",
    "    row.education_type = \"High School Dropout Percent\" if param['education_type'] == 'dropout' else \"Percent with Any Degree\"\n",
    "    row.income_type = \"Median Income\" if param['income_type'] == \"median\" else \"Income Standard Deviation\"\n",
    "    row.crime_regularization = \"Square Root of Log\" if param['crime_type'] == 'log' else \"Fourth Root of Log\"\n",
    "    X = reader.get_features(param['education_type'], param['income_type'])\n",
    "    y = reader.get_label('total', param['crime_type'])\n",
    "    y=np.power(y,1/2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    \n",
    "    ## Scale input data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.to_numpy())\n",
    "    X_test = scaler.fit_transform(X_test.to_numpy())\n",
    "    \n",
    "    ## Liner Regression\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred=linreg.predict(X_test)\n",
    "    row.LinearRegMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ## Ridge Regression\n",
    "    ridgereg = Ridge(alpha=1.0)\n",
    "    ridgereg=ridgereg.fit(X_train,y_train)\n",
    "    y_pred=ridgereg.predict(X_test)\n",
    "    row.RidgeMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ## Decision Tree\n",
    "    regr = DecisionTreeRegressor(max_depth=2)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    row.DecisionTreeMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ## Random Forest Tree\n",
    "    regr = RandomForestRegressor(max_depth=2)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    row.RandomForestMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ### Boosting\n",
    "    params = {'n_estimators': 100, 'max_depth': 2}\n",
    "    clf = GradientBoostingRegressor(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    row.BoostingMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ### KNN\n",
    "    neigh = KNeighborsRegressor(n_neighbors=3)\n",
    "    neigh.fit(X_train, y_train) \n",
    "    y_pred=neigh.predict(X_test)\n",
    "    row.KNeighbourMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ### SVR\n",
    "    svr = SVR(gamma='auto')\n",
    "    svr = svr.fit(X_train, y_train.values.ravel())\n",
    "    y_pred=svr.predict(X_test)\n",
    "    row.SVR_MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "   \n",
    "    \n",
    "    result = result.append(row.toDict(), ignore_index=True)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SVR Support Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.02061790664666147\nNumber of support vectors :  745\n \nSupport Vectors : \n [[ 0.02521343 -0.20740018]\n [ 0.59036416 -1.07106894]\n [-1.57823747  0.33439075]\n ...\n [-0.85537026  0.08756263]\n [ 0.49836288 -1.34122952]\n [ 2.49610499 -0.26986506]]\n"
    }
   ],
   "source": [
    "X = reader.get_features(\"dropout\", \"median\")\n",
    "y = reader.get_label('total', \"sqrt_log\")\n",
    "y=np.power(y,1/2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.to_numpy())\n",
    "X_test = scaler.fit_transform(X_test.to_numpy())\n",
    "\n",
    "\n",
    "svr = SVR(gamma='auto')\n",
    "svr = svr.fit(X_train, y_train.values.ravel())\n",
    "y_pred=svr.predict(X_test)\n",
    "\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n",
    "supportVectors = len(svr.support_vectors_)\n",
    "SV=svr.support_vectors_\n",
    "print(\"Number of support vectors : \",supportVectors)\n",
    "print(\" \")\n",
    "print(\"Support Vectors : \\n\", SV)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.020799078988974547\n"
    },
    {
     "data": {
      "text/plain": "array([[0.02535872, 0.04726192]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reader.get_features(\"dropout\", \"median\")\n",
    "y = reader.get_label('total', \"sqrt_log\")\n",
    "y=np.power(y,1/2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.to_numpy())\n",
    "X_test = scaler.fit_transform(X_test.to_numpy())\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred=linreg.predict(X_test)\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.23326286901169918\nNumber of support vectors :  2\n \nSupport Vectors : \n [0.00183921 0.0076809 ]\n"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "X = reader.get_features(\"dropout\", \"median\")\n",
    "y = reader.get_label('total', \"sqrt_log\")\n",
    "y=np.power(y,1/2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.to_numpy())\n",
    "X_test = scaler.fit_transform(X_test.to_numpy())\n",
    "\n",
    "\n",
    "svr = LinearSVR(C=0.0005)\n",
    "svr = svr.fit(X_train, y_train.values.ravel())\n",
    "y_pred=svr.predict(X_test)\n",
    "\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n",
    "SV=svr.coef_\n",
    "print(\"Weights : \\n\", SV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}