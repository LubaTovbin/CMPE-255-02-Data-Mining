{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7dd847de2c9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRidge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SJSU\\cmpe 255\\CMPE-255-02-Data-Mining\\code\\reader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_processed_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_processed_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SJSU\\cmpe 255\\CMPE-255-02-Data-Mining\\code\\preprocess.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.power(np.log1p(reader.get_all_data()), 1/2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting histograms to see the data distribution of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(figsize=(15,15), xrot=-45, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding correlation between all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = data.corr() \n",
    "corrmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the correlation matrix using heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = data.corr() \n",
    "  \n",
    "f, ax = plt.subplots(figsize =(9, 8)) \n",
    "sns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the correlation between features using scatter plot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(data, figsize=(22, 22))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting correlations between similar types of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['Property Crime'],data['Violent Crime'])  \n",
    "plt.xlabel('Property Crime')\n",
    "plt.ylabel('Violent Crime')\n",
    "plt.title('Correlation between Property Crime and Violent Crime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['Percent High School Dropouts'],data['Percent No Degree'])  \n",
    "plt.xlabel('Percentage of High School dropouts')\n",
    "plt.ylabel('Percentage of people without degree')\n",
    "plt.title('Correlation between percentage of people who dropped out of high school and people without degree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['Mean Income (Household)'],data['Median Income (Household)'])  \n",
    "plt.xlabel('Mean Income per household')\n",
    "plt.ylabel('Median Income per household')\n",
    "plt.title('Correlation between mean and median income per household')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['Mean Income (Household)'],data['Income Standard Deviation (Household)'])  \n",
    "plt.xlabel('Mean Income per household')\n",
    "plt.ylabel('Standard Deviation in Income per household')\n",
    "plt.title('Correlation between mean and standarad deviation income per household')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting correlation between Per Capita Income, Education Level and Total Crime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 115, 10000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(xline, yline, zline, 'gray')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = data['Percent High School Dropouts']\n",
    "xdata = data['Total Crime']\n",
    "ydata = data['Per Capita Income']\n",
    "ax.scatter3D(xdata, ydata, zdata, c=zdata, cmap='viridis', linewidth=10);\n",
    "ax.set_xlabel('Total Crime')\n",
    "ax.set_ylabel('Per Capita Income')\n",
    "ax.set_zlabel('Percent No Degree');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 115, 10000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(xline, yline, zline, 'gray')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = data['Percent No Degree']\n",
    "xdata = data['Total Crime']\n",
    "ydata = data['Per Capita Income']\n",
    "ax.scatter3D(xdata, ydata, zdata, c=zdata, cmap='viridis', linewidth=10);\n",
    "ax.set_xlabel('Total Crime')\n",
    "ax.set_ylabel('Per Capita Income')\n",
    "ax.set_zlabel('Percent No Degree');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting features and label and performing few transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reader.get_features('dropout', 'mean')\n",
    "y = reader.get_label('violent')\n",
    "y = np.power(np.log1p(y),1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class Row(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.education_type = None\n",
    "        self.income_type = None\n",
    "        self.LinearRegMSE = None\n",
    "        self.RidgeMSE = None\n",
    "        self.DicisionTreeMSE = None\n",
    "        self.KNeighbourMSE = None\n",
    "        self.SVR_MSE = None\n",
    "        self.RandomForestMSE = None\n",
    "        self.BoostingMSE = None\n",
    "\n",
    "    def toDict(self):\n",
    "        return {'education_type' : self.education_type,\n",
    "                'income_type' : self.income_type,\n",
    "                'LinearRegMSE':  self.LinearRegMSE,\n",
    "                'RidgeMSE' : self.RidgeMSE,\n",
    "                'DicisionTreeMSE' : self.DicisionTreeMSE,\n",
    "                'KNeighbourMSE': self.KNeighbourMSE,\n",
    "                'SVR_MSE' : self.SVR_MSE,\n",
    "                'RandomForestMSE': self.RandomForestMSE,\n",
    "                'BoostingMSE' :self.BoostingMSE\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "param_grid = {\"education_type\" :[\"dropout\", \"degreeless\"], \"income_type\" :[\"mean\", \"median\", \"percapita\", \"deviation\"]}\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for param in list(ParameterGrid(param_grid)):\n",
    "    row = Row()\n",
    "    row.education_type = param['education_type']\n",
    "    row.income_type = param['income_type']\n",
    "    X = reader.get_features(param['education_type'], param['income_type'])\n",
    "    y = reader.get_label('violent')\n",
    "    y = np.power(np.log1p(y),1/2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    \n",
    "    ## Scale input data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.to_numpy())\n",
    "    X_test = scaler.fit_transform(X_test.to_numpy())\n",
    "    \n",
    "    ## Liner Regression\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred=linreg.predict(X_test)\n",
    "    row.LinearRegMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ## Ridge Regression\n",
    "    ridgereg = Ridge(alpha=1.0)\n",
    "    ridgereg=ridgereg.fit(X_train,y_train)\n",
    "    y_pred=ridgereg.predict(X_test)\n",
    "    row.RidgeMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ## Decision Tree\n",
    "    regr = DecisionTreeRegressor(max_depth=2)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    row.DicisionTreeMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ## Random Forest Tree\n",
    "    regr = RandomForestRegressor(max_depth=2)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    row.RandomForestMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ### Boosting\n",
    "    params = {'n_estimators': 100, 'max_depth': 2}\n",
    "    clf = GradientBoostingRegressor(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    row.BoostingMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ### KNN\n",
    "    neigh = KNeighborsRegressor(n_neighbors=3)\n",
    "    neigh.fit(X_train, y_train) \n",
    "    y_pred=neigh.predict(X_test)\n",
    "    row.KNeighbourMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ### SVR\n",
    "    svr = SVR(gamma='auto')\n",
    "    svr = svr.fit(X_train, y_train.values.ravel())\n",
    "    y_pred=svr.predict(X_test)\n",
    "    row.SVR_MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    result = result.append(row.toDict(), ignore_index=True)\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
